{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1><b><center>Programming Assignment I : </center></b></h1>\n",
    "<h1><b><center>Gaussian Process Regression</center></b></h1>\n",
    "<h5><b><center> Amatya Sharma </center></b></h5>\n",
    "<h5><b><center> 17CS30042 </center></b></h5>\n",
    "\n",
    "Dependencies and Variables : \n",
    "- We are predicting for Xtest, if user wants to predict for custom values, modify Xtest and Ytest correspndingly in cell 3.\n",
    "- Xtrain := Trianing Data with only one feature i.e. Day Number\n",
    "- Ytrain := Training Values Corresponding to Xtrain\n",
    "- Ytrain_India := Ytrain for India\n",
    "- Ytrain_World := Ytrain for World\n",
    "- Xtest := Test Data with only one feature i.e. Day Number\n",
    "- Ytest := Actual Test Values Corresponding to Xtest will be used for checking accuracy of the models\n",
    "- Ytest_India := Ytest for India\n",
    "- Ytest_World := Ytest for World\n",
    "- K = Kernel(Xtrain, Xtrain)\n",
    "- K_s = kernel(Xtrain, Xtest)\n",
    "- K_ss = kernel(Xtest, Xtest)\n",
    "- sigma_f := 1st hyperparam for the squared exponential kernel function\n",
    "- l := 1st hyperparam for the squared exponential kernel function\n",
    "- sigma_y := given gaussian noise error variance\n",
    "- mu_s := PPD predicted mean vector corresp to PPD Gaussian Distribution\n",
    "- sigma_s := PPD predicted mean vector corresp to PPD Gaussian Distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import cholesky, det, lstsq\n",
    "import pandas\n",
    "\n",
    "# !pip install pymc3\n",
    "import pymc3 as pm\n",
    "\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "%matplotlib inline\n",
    "np.random.seed(10)\n",
    "# from scipy.optimize import minimize/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pandas.read_csv('new_casesWorld-India.csv')\n",
    "data = df.values\n",
    "\n",
    "# partition into training and test sets\n",
    "# partiton into data from world and india\n",
    "Xtrain = data[0:245,0]\n",
    "Ytrain_World = data[0:245,2]\n",
    "Ytrain_India = data[0:245,3]\n",
    "\n",
    "Xtest = data[246:, 0]\n",
    "Ytest_World = data[246:, 2]\n",
    "Ytest_India = data[246:, 3]\n",
    "\n",
    "# convert all arrays to numpy arrays to enable them to perform numpy array/matrix operations\n",
    "Xtrain = np.array(Xtrain)\n",
    "Ytrain_World = np.array(Ytrain_World)\n",
    "Ytrain_India = np.array(Ytrain_India)\n",
    "Xtest = np.array(Xtest)\n",
    "Ytest_World = np.array(Ytest_World)\n",
    "Ytest_India = np.array(Ytest_India)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(245, 1) (245,) (70, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [sigma]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='2243' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      28.04% [2243/8000 34:58<1:29:46 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Not enough samples to build a trace.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\amatya sharma\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pymc3\\sampling.py\u001b[0m in \u001b[0;36m_mp_sample\u001b[1;34m(draws, tune, step, chains, cores, chain, random_seed, start, progressbar, trace, model, callback, discard_tuned_samples, mp_ctx, pickle_backend, **kwargs)\u001b[0m\n\u001b[0;32m   1485\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1486\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mdraw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msampler\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1487\u001b[0m                     \u001b[0mtrace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraces\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchain\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mchain\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amatya sharma\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pymc3\\parallel_sampling.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m             \u001b[0mdraw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mProcessAdapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_draw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m             \u001b[0mproc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_last\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amatya sharma\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pymc3\\parallel_sampling.py\u001b[0m in \u001b[0;36mrecv_draw\u001b[1;34m(processes, timeout)\u001b[0m\n\u001b[0;32m    351\u001b[0m         \u001b[0mpipes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_msg_pipe\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mproc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprocesses\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[0mready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultiprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mready\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amatya sharma\\appdata\\local\\programs\\python\\python37-32\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 868\u001b[1;33m             \u001b[0mready_handles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_exhaustive_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwaithandle_to_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    869\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amatya sharma\\appdata\\local\\programs\\python\\python37-32\\lib\\multiprocessing\\connection.py\u001b[0m in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m    799\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_winapi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWaitForMultipleObjects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mWAIT_TIMEOUT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-bb0d9a707418>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0my_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmarginal_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mXu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mtrace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amatya sharma\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pymc3\\sampling.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(draws, step, init, n_init, start, trace, chain_idx, chains, cores, tune, progressbar, model, random_seed, discard_tuned_samples, compute_convergence_checks, callback, return_inferencedata, idata_kwargs, mp_ctx, pickle_backend, **kwargs)\u001b[0m\n\u001b[0;32m    543\u001b[0m         \u001b[0m_print_step_hierarchy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m             \u001b[0mtrace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_mp_sample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0msample_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparallel_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPickleError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m             \u001b[0m_log\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Could not pickle model, sampling singlethreaded.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amatya sharma\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pymc3\\sampling.py\u001b[0m in \u001b[0;36m_mp_sample\u001b[1;34m(draws, tune, step, chains, cores, chain, random_seed, start, progressbar, trace, model, callback, discard_tuned_samples, mp_ctx, pickle_backend, **kwargs)\u001b[0m\n\u001b[0;32m   1510\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1511\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdiscard_tuned_samples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1512\u001b[1;33m             \u001b[0mtraces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_choose_chains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtune\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1513\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1514\u001b[0m             \u001b[0mtraces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_choose_chains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraces\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amatya sharma\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pymc3\\sampling.py\u001b[0m in \u001b[0;36m_choose_chains\u001b[1;34m(traces, tune)\u001b[0m\n\u001b[0;32m   1528\u001b[0m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtune\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtrace\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtraces\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1530\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Not enough samples to build a trace.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1532\u001b[0m     \u001b[0midxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Not enough samples to build a trace."
     ]
    }
   ],
   "source": [
    "# A one dimensional column vector of inputs.\n",
    "# X = Xtrain\n",
    "# X = X.reshape((245,1))\n",
    "# X = X/250\n",
    "X = np.linspace(0,244,245)[:,None]\n",
    "# X = np.linspace(0, 1, 10)[:, None]\n",
    "print(type(X))\n",
    "y = Ytrain_India\n",
    "# y = np.random.rand(10)\n",
    "\n",
    "# A smaller set of inducing inputs\n",
    "# Xu = np.linspace(0, 1, 245)[:, None]\n",
    "# Xu = Xtrain[40:100]\n",
    "# Xu = Xu.reshape((60,1))\n",
    "# Xu = Xu/250\n",
    "Xu = np.linspace(130,200,70)[:,None]\n",
    "\n",
    "print(np.shape(X), np.shape(y), np.shape(Xu))\n",
    "\n",
    "\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # Specify the covariance function.\n",
    "    cov_func = pm.gp.cov.ExpQuad(1, ls=0.1)\n",
    "\n",
    "    # Specify the GP.  The default mean function is `Zero`.\n",
    "    # gp = pm.gp.Latent(cov_func=cov_func)\n",
    "    gp = pm.gp.MarginalSparse(cov_func=cov_func, approx=\"FITC\")\n",
    "\n",
    "    # Place a GP prior over the function f.\n",
    "    sigma = pm.HalfCauchy(\"sigma\", beta=3)\n",
    "    y_ = gp.marginal_likelihood(\"y\", X=X, Xu=Xu, y=y, noise=sigma)\n",
    "    \n",
    "    trace = pm.sample(1000)\n",
    "    print(trace, \"\\n\")\n",
    "\n",
    "...\n",
    "\n",
    "\n",
    "\n",
    "# pm.traceplot(trace);\n",
    "\n",
    "# After fitting or sampling, specify the distribution\n",
    "# at new points with .conditional\n",
    "Xnew = np.linspace(-1, 2, 50)[:, None]\n",
    "\n",
    "with model:\n",
    "    fcond = gp.conditional(\"fcond\", Xnew=Xnew)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel function for guasiian processes\n",
    "# kernel function is only for vectors not for matrices as our inputs are 1-D\n",
    "# we use squared exponential kernel\n",
    "# with hyperparameters sigma_f and l \n",
    "\n",
    "\n",
    "# funtion to caluculate kernel of 2 scalars\n",
    "\n",
    "def rbf_kernel_util(sigma_f, x1, x2):\n",
    "    return np.exp(-(x1-x2)**2/(2* sigma_f**2))\n",
    "\n",
    "def sqexp_kernel_util(x1, x2, l, sigma_f):\n",
    "    return sigma_f*sigma_f * np.exp(-0.5/(l*l) * (x1-x2)*(x1-x2))\n",
    "\n",
    "# funtion to calculate SE Kernel of two input vectors\n",
    "def kernel(X1, X2, l, sigma_f):\n",
    "    l1 = len(X1)\n",
    "    l2 = len(X2)\n",
    "    K = np.zeros((l1, l2))\n",
    "    \n",
    "    #iterate over all indices of the covariance matrix to fill it with k(i,j)\n",
    "    for i in range(l1):\n",
    "        for j in range(l2):\n",
    "            K[i][j] = sqexp_kernel_util(X1[i], X2[j], l, sigma_f)\n",
    "    return K\n",
    "\n",
    "def kernel_visualize(X_visualize, X_visualize2, l, sigma_f):\n",
    "    K_visualize = kernel(X_visualize, X_visualize2, l, sigma_f)\n",
    "\n",
    "    figre, axs = plt.subplots()\n",
    "    plt.imshow(K_visualize, interpolation='none')\n",
    "    plt.title(\"Covariance Matrix\")\n",
    "    axs.set_ylim(axs.get_ylim()[::-1])\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "#to-do write some features of hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizing the kernel matrix for first 20 values\n",
    "# the concentration can be seen along diagonal values due to the properties of Squared Exponential Kernel\n",
    "sigma_f = 5\n",
    "l = 50\n",
    "\n",
    "print(\"Histogram of K(Xtrain, Xtrain):\")\n",
    "kernel_visualize(Xtrain, Xtrain, l, sigma_f)\n",
    "\n",
    "print(\"Histogram of K(Xtest, Xtest):\")\n",
    "kernel_visualize(Xtest, Xtest, l, sigma_f)\n",
    "\n",
    "print(\"Histogram of K(Xtrain, Xtest):\")\n",
    "kernel_visualize(Xtrain, Xtest, l, sigma_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize GP of  Finite number of points\n",
    "\n",
    "Xplot = Xtest\n",
    "numplot = len(Xplot)\n",
    "Kplot = kernel(Xplot, Xplot, .1, 1)\n",
    "\n",
    "rand_draw_prior = np.dot(Kplot, np.random.normal(size=(numplot, 4)))\n",
    "\n",
    "figre, axs = plt.subplots()\n",
    "variances = np.diag(Kplot) # diagonal elements are individual vairance\n",
    "std_dev = np.sqrt(variances)\n",
    "\n",
    "# plt.fill_between(Xplot.reshape(-1), 1.96 * std_dev,  - 1.96 * std_dev, alpha=0.1)\n",
    "\n",
    "plt.plot(Xplot, rand_draw_prior)\n",
    "plt.plot(Xplot, np.zeros(len(Xplot)), label='Mean')\n",
    "plt.title(\"GP Prior Train of 4 samples\")\n",
    "plt.xlabel(\"Variable\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cinv(K, sigma_y):\n",
    "    K_inv = np.linalg.inv(K + (sigma_y*sigma_y)*np.eye(len(Xtrain)))\n",
    "    return K_inv\n",
    "\n",
    "def posterior_predictive(Xtrain, Ytrain, l, sigma_y, sigma_f, X):\n",
    "    cov_s = 0.0\n",
    "    K_ss = kernel(X, X, l, sigma_f)\n",
    "    K_s = kernel(Xtrain, X, l, sigma_f)\n",
    "\n",
    "    mu_s = 0.0\n",
    "    K = kernel(Xtrain, Xtrain, l, sigma_f)\n",
    "    K_inv = Cinv(K, sigma_y)\n",
    "    \n",
    "    sigma_s = K_ss - K_s.T.dot(K_inv).dot(K_s)\n",
    "    mu_s = K_s.T.dot(K_inv).dot(Ytrain)\n",
    "    \n",
    "    return mu_s, sigma_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_plot(Xtrain, Ytrain, l, sigma_f, sigma_y, Xtest, Ytest): \n",
    "    mu, sigma = posterior_predictive(Xtrain, Ytrain, l, sigma_y, sigma_f, Xtest)\n",
    "\n",
    "    figr, axs = plt.subplots()\n",
    "\n",
    "    plt.plot(Xtrain, Ytrain, 'c')\n",
    "    plt.plot(Xtest, Ytest, 'c--')\n",
    "    plt.plot(Xtest, mu, 'g')\n",
    "    plt.xlabel(\"Day Number\")\n",
    "    plt.ylabel(\"Number of Cases\")\n",
    "    plt.legend([\"Training\", \"Test\",\"Prediction\"])\n",
    "    plt.title(\"Data and Predictions : Big Picture\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    if Xtrain.all() == Xtest.all():\n",
    "        return mu, sigma\n",
    "\n",
    "    plt.plot(Xtest, Ytest)\n",
    "    plt.plot(Xtest, mu)\n",
    "#     pred = np.array(mu)\n",
    "#     pred = pred.T\n",
    "#     sgma = np.array(sigma)\n",
    "#     plt.errorbar(Xtest, pred, yerr = sgma, capsize = 0)\n",
    "    plt.xlabel(\"Day Number\")\n",
    "    plt.ylabel(\"Number of Cases\")\n",
    "    plt.legend([\"Test\", \"Prediction\"])\n",
    "    plt.title(\"Zoomed in View on Test set\")\n",
    "    plt.show()  \n",
    "    \n",
    "    plt.imshow(sigma, interpolation='none')\n",
    "    plt.title(\"Covariance Matrix PPD\")\n",
    "    axs.set_ylim(axs.get_ylim()[::-1])\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n",
    "    return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 1 \n",
    "l= 95\n",
    "sigma_f= .6\n",
    "sigma_y=.1\n",
    "\n",
    "print(\"Fitting Train Data - India on Self-fed HyperParameters:\")\n",
    "mu_india, sigma_india = predict_and_plot(Xtrain, Ytrain_India, l, sigma_f, sigma_y, Xtrain, Ytrain_India)                         \n",
    "\n",
    "\n",
    "print(\"Predictions - India on Self-fed HyperParameters:\")\n",
    "mu_india, sigma_india = predict_and_plot(Xtrain, Ytrain_India, l, sigma_f, sigma_y, Xtest, Ytest_India)                         \n",
    "\n",
    "# kernel_visualize()\n",
    "\n",
    "print(\"(India)Mean values of predictions with guessed hyperparams day 246 onwards:\\n\", mu_india, \"\\n\\nSigma:\\n\", sigma_india)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 75 15\n",
    "l= 75\n",
    "sigma_f= 15\n",
    "sigma_y=.1\n",
    "\n",
    "print(\"Fiited Train Data - World on Self-fed HyperParameters:\")\n",
    "mu_world, sigma_world = predict_and_plot(Xtrain, Ytrain_World, l, sigma_f, sigma_y, Xtrain, Ytrain_World)                         \n",
    "\n",
    "print(\"Predictions - World on Self-fed HyperParameters:\")\n",
    "mu_world, sigma_world = predict_and_plot(Xtrain, Ytrain_World, l, sigma_f, sigma_y, Xtest, Ytest_World)                         \n",
    "\n",
    "print(\"(World)Mean values of predictions with guessed hyperparams day 246 onwards:\\n\", mu_world, \"\\n\\nSigma:\\n\", sigma_world) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# nx, nu = 60, 7\n",
    "# x = np.random.rand(nx)\n",
    "# xu = np.random.rand(nu)\n",
    "# # y = np.sin(2 * np.pi * x * 2.5) + 0.3 * np.random.randn(nx)\n",
    "\n",
    "# plt.plot(x, y, 'ko', ms=2);\n",
    "# plt.plot(xu, 0.0*np.ones(len(xu)), 'rx', ms=10)\n",
    "# x = x[:,None]; xu = xu[:,None]\n",
    "# xs = np.linspace(-0.1, 1.1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pymc3.gp' has no attribute 'GP'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-55cb373753fc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mσ_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHalfCauchy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"σ_n\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcov\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mσ_f\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcov\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMatern52\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mℓ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mgp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGP\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"gp\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mσ_n\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minducing_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobserved\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mtrace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pymc3.gp' has no attribute 'GP'"
     ]
    }
   ],
   "source": [
    "# with pm.Model() as model:\n",
    "#     ℓ = pm.Gamma(\"ℓ\", alpha=1.5, beta=0.5)\n",
    "#     σ_f = pm.HalfCauchy(\"σ_f\", beta=5)\n",
    "#     σ_n = pm.HalfCauchy(\"σ_n\", beta=5)\n",
    "#     cov = tt.square(σ_f) * pm.gp.cov.Matern52(1, ℓ)\n",
    "#     gp = pm.gp.GP(\"gp\", x, cov, sigma=σ_n, inducing_points=xu, observed=y)\n",
    "#     trace = pm.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (60,) (10,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-09b7efd39135>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;31m# Place a GP prior over the function f.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0msigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHalfCauchy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sigma\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0my_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmarginal_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mXu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amatya sharma\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pymc3\\gp\\gp.py\u001b[0m in \u001b[0;36mmarginal_likelihood\u001b[1;34m(self, name, X, Xu, y, noise, is_observed, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m                                  X=X, Xu=Xu, sigma=noise)\n\u001b[0;32m    727\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_observed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDensityDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobserved\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    729\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m             \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minfer_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amatya sharma\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pymc3\\distributions\\distribution.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, name, *args, **kwargs)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getnewargs__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amatya sharma\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pymc3\\model.py\u001b[0m in \u001b[0;36mVar\u001b[1;34m(self, name, dist, data, total_size, dims)\u001b[0m\n\u001b[0;32m   1115\u001b[0m                     \u001b[0mdistribution\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m                     \u001b[0mtotal_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1117\u001b[1;33m                     \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1118\u001b[0m                 )\n\u001b[0;32m   1119\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobserved_RVs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amatya sharma\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pymc3\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, type, owner, index, name, data, distribution, total_size, model)\u001b[0m\n\u001b[0;32m   1738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1739\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissing_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1740\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogp_elemwiset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1741\u001b[0m             \u001b[1;31m# The logp might need scaling in minibatches.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1742\u001b[0m             \u001b[1;31m# This is done in `Factor`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amatya sharma\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pymc3\\gp\\gp.py\u001b[0m in \u001b[0;36m_build_marginal_likelihood_logp\u001b[1;34m(self, y, X, Xu, sigma)\u001b[0m\n\u001b[0;32m    673\u001b[0m         \u001b[0mA_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mLamd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m         \u001b[0mL_B\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcholesky\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meye\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA_l\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    676\u001b[0m         \u001b[0mr_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mLamd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m         \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msolve_lower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL_B\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_l\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amatya sharma\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\theano\\tensor\\var.py\u001b[0m in \u001b[0;36m__sub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;31m# and the return value in that case\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mNotImplementedError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAsTensorError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amatya sharma\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\theano\\gof\\op.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    672\u001b[0m                 \u001b[0mthunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstorage_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m                 \u001b[0mrequired\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mthunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrequired\u001b[0m  \u001b[1;31m# We provided all inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amatya sharma\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\theano\\gof\\op.py\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    890\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 892\u001b[1;33m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    893\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m                     \u001b[0mcompute_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amatya sharma\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\theano\\tensor\\elemwise.py\u001b[0m in \u001b[0;36mperform\u001b[1;34m(self, node, inputs, output_storage)\u001b[0m\n\u001b[0;32m    788\u001b[0m             \u001b[0mnout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 790\u001b[1;33m         \u001b[0mvariables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mufunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mufunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnout\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (60,) (10,) "
     ]
    }
   ],
   "source": [
    "# A one dimensional column vector of inputs.\n",
    "X = np.linspace(0, 1, 10)[:, None]\n",
    "\n",
    "# A smaller set of inducing inputs\n",
    "Xu = np.linspace(0, 1, 5)[:, None]\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # Specify the covariance function.\n",
    "    cov_func = pm.gp.cov.ExpQuad(1, ls=0.1)\n",
    "\n",
    "    # Specify the GP.  The default mean function is `Zero`.\n",
    "    gp = pm.gp.MarginalSparse(cov_func=cov_func, approx=\"FITC\")\n",
    "\n",
    "    # Place a GP prior over the function f.\n",
    "    sigma = pm.HalfCauchy(\"sigma\", beta=3)\n",
    "    y_ = gp.marginal_likelihood(\"y\", X=X, Xu=Xu, y=y, noise=0.1)\n",
    "\n",
    "...\n",
    "\n",
    "# After fitting or sampling, specify the distribution\n",
    "# at new points with .conditional\n",
    "Xnew = np.linspace(-1, 2, 50)[:, None]\n",
    "\n",
    "with model:\n",
    "    fcond = gp.conditional(\"fcond\", Xnew=Xnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hyper parameter optimization util function\n",
    "# def hyperparameter_opt(sigma_f, l, Xtrain, Ytrain, Xtest, Ytest):\n",
    "#     print(\"------------LOG OF OPTIMIZATION ALGORITHM - BEGIN------------\")\n",
    "#     min_err = 9999999999.0\n",
    "#     sig_opt = 9999.0 \n",
    "#     l_opt = 9999.0 \n",
    "#     sig = max(sigma_f - 5.0, .1)\n",
    "#     sigma_lwr = sig\n",
    "#     ll = max(l - 50.0, 1)\n",
    "#     ll_lwr = ll\n",
    "#     while sig <= sigma_lwr + 10.0:\n",
    "#         ll = ll_lwr\n",
    "#         while ll <= ll_lwr + 100.0:\n",
    "#             mu_pred, sigma_pred = posterior_predictive(Xtrain, Ytrain, ll, sigma_y, sig, Xtest)\n",
    "#             err = abs(Ytest - mu_pred)\n",
    "#             err = err.sum()\n",
    "#             print(sig, ll, err)\n",
    "            \n",
    "#             if err < min_err:\n",
    "#                 min_err = err\n",
    "#                 sig_opt = sig\n",
    "#                 l_opt = ll\n",
    "#                 print(\"new minima::\", err, sig_opt, l_opt)\n",
    "            \n",
    "#             ll+=10.0\n",
    "#         sig+=.5\n",
    "    \n",
    "    \n",
    "#     print(\"------------LOG OF OPTIMIZATION ALGORITHM - END------------\")\n",
    "#     return sig_opt, l_opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hyperparameter optimization India\n",
    "# sigma_f = .6\n",
    "# l = 96\n",
    "# sig_opt, l_opt = hyperparameter_opt(sigma_f, l, Xtrain, Ytrain_India, Xtest, Ytest_India)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1.6 21\n",
    "# # sig_opt = 1.6\n",
    "# # l_opt = 21.0\n",
    "# print(\"Optimized Hyperparams India (sigma_f, l):\", sig_opt, l_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Fitted Train Data - India on Optimized HyperParameters:\")\n",
    "# mu_world, sigma_world = predict_and_plot(Xtrain, Ytrain_India, l_opt, sig_opt, sigma_y, Xtrain, Ytrain_India) \n",
    "\n",
    "# print(\"Predictions - India on Optimized HyperParameters:\")\n",
    "# mu_india, sigma_india = predict_and_plot(Xtrain, Ytrain_India, l_opt, sig_opt, sigma_y, Xtest, Ytest_India)\n",
    "\n",
    "# print(\"(INdia) Means of Predictions from optimized hyperparams day 246 onwards:\\n\",mu_india, \"\\n\\nSigma :\\n\", sigma_india)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hyper paramter optimization worlld\n",
    "# sigma_f = 15.0\n",
    "# l = 75.0\n",
    "# sig_opt, l_opt = hyperparameter_opt(sigma_f, l, Xtrain, Ytrain_World, Xtest, Ytest_World)                   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 5 201    \n",
    "# # sig_opt = 5.0\n",
    "# # l_opt = 201.0\n",
    "# print(\"Optimized HyperParams World : (sigma_f, l)\",sig_opt, l_opt)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Fitted Train Data - World on Optimized HyperParameters:\")\n",
    "# mu_world, sigma_world = predict_and_plot(Xtrain, Ytrain_World, l_opt, sig_opt, sigma_y, Xtrain, Ytrain_World) \n",
    "\n",
    "# print(\"Predictions - World on Optimized HyperParameters:\")\n",
    "# mu_world, sigma_world = predict_and_plot(Xtrain, Ytrain_World, l_opt, sig_opt, sigma_y, Xtest, Ytest_World) \n",
    "\n",
    "# print(\"(World)Mean values of predictions day 246 onwards:\\n\", mu_world, \"\\n\\n Sigma:\\n\", sigma_world)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def nll(params,X,Y):\n",
    "#     length_scale = params[0] ## Account for length scale here\n",
    "#     sig_n = params[1] ## Noise std. deviation\n",
    "#     K = kernel(X, X, length_scale, sig_n) + np.diag(sig_n**2*np.ones(len(X))) ## Note the change here\n",
    "#     c = np.linalg.inv(np.linalg.cholesky(K))#+eps*(np.eye(len(X)))))\n",
    "#     Ki = np.dot(c.T,c)\n",
    "#     (sign, logdetK) = np.linalg.slogdet(K)\n",
    "#     ll = -numObs/2 * np.log(np.dot(Y.T,(np.dot(Ki,Y)))) - 1/2 * logdetK\n",
    "#     return -ll\n",
    "\n",
    "# def gnll(params,X,Y):\n",
    "#     length_scale = params[0] ## Account for length scale here\n",
    "#     sig_n = params[1]\n",
    "#     K = kernel(X, X, length_scale, sig_n) + np.diag(sig_n**2*np.ones(len(X))) ## Note the change here\n",
    "#     c = np.linalg.inv(np.linalg.cholesky(K))#+eps*(np.eye(numObs))))\n",
    "#     Ki = np.dot(c.T,c)\n",
    "#     KiY = np.dot(Ki,Y)\n",
    "#     dotK = np.dot(K,DistMat)/(length_scale**2)\n",
    "\n",
    "#     # Compute derivatives for both components separately\n",
    "#     dll_ls = (numObs)/2 * np.dot(KiY.T,np.dot(dotK,KiY))/(np.dot(Y.T,KiY))\\\n",
    "#             - (1/2)*(np.sum(np.diag(np.dot(Ki,dotK)))) # for length scale\n",
    "#     dll_n = (numObs)/2 * np.dot(KiY.T,KiY)/(np.dot(Y.T,KiY)) - 1/2*(np.sum(np.diag(Ki))) # for noise\n",
    "#     return(np.concatenate((dll_ls, dll_n), axis=0))\n",
    "\n",
    "\n",
    "# initial_guess = [(0.1,0.1*np.var(YScaled_noisy))]\n",
    "# HP_bounds = ((eps, 10),(eps, np.var(YScaled_noisy)))\n",
    "\n",
    "\n",
    "# DistMat = Sq_Euclid_DistMat(Xtrain,Xtrain)\n",
    "# res = minimize(nll, initial_guess,args=(DistMat,YScaled_noisy), method=\"L-BFGS-B\",\\\n",
    "#                jac=gnll,bounds = HP_bounds,options={'maxiter':1000, 'gtol': 1e-6, 'disp': True})\n",
    "\n",
    "# print(\"Optimal length scale: \",res.x[0])\n",
    "# print(\"Optimal Noise Variance: \",res.x[1])\n",
    "# print(\"Optimal Negative Log-Likelihood: \",res.fun[0][0]) # log marginal likelihood.\n",
    "# print(\"Convergence Status: \",res.message)\n",
    "# print(\"No. of Evaluations: \", res.nfev)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
